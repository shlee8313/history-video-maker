#!/usr/bin/env python3
"""
Video Story Maker - Pipeline CLI

ì‚¬ìš©ë²•:
    python pipeline.py <command> [options]

Phase 1: SCRIPT
    (ìŠ¤í‚¬ ì‚¬ìš©: /script-writer)

Phase 2: STRUCTURE
    (ì—ì´ì „íŠ¸ ì‚¬ìš©: scene-director)

Phase 3: AUDIO
    audio           TTS ìƒì„± + Whisper íƒ€ì„ìŠ¤íƒ¬í”„

Phase 4: CODE
    (ì—ì´ì „íŠ¸ ì‚¬ìš©: scene-splitter, scene-coder)
    update-root     Root.tsx ìë™ ì—…ë°ì´íŠ¸

Phase 5: RENDER
    render          Remotion ë Œë”ë§ (ê¸°ë³¸: ë°°ê²½ í¬í•¨, --transparent: íˆ¬ëª…)
    composite       FFmpeg ë°°ê²½ í•©ì„± (íˆ¬ëª… ë Œë”ë§ ì‹œì—ë§Œ í•„ìš”)
    section-merge   ì„¹ì…˜ í•©ì„± (concat + audio)

Phase 6: FINAL
    final           ìµœì¢… ë³‘í•© (ì „í™˜ + BGM)

ìœ í‹¸ë¦¬í‹°:
    status          í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸
    clean           output í´ë” ì´ˆê¸°í™” (ì—ì…‹ ìœ ì§€)
    init            í”„ë¡œì íŠ¸ ì™„ì „ ì´ˆê¸°í™” (ì—ì…‹ í¬í•¨)
    asset-catalog   ì—ì…‹ ì¹´íƒˆë¡œê·¸ ìƒì„±

ì˜ˆì‹œ:
    python pipeline.py audio --voice nova
    python pipeline.py render                    # ë°°ê²½ í¬í•¨ ë Œë”ë§ (ê¸°ë³¸)
    python pipeline.py render --transparent      # íˆ¬ëª… ë Œë”ë§ (FFmpeg í•©ì„± í•„ìš”)
    python pipeline.py render --section hook
    python pipeline.py final --bgm-volume 0.08
"""

import json
import sys
import argparse
import os
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any

# .env ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# OpenAI for TTS/Whisper
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ============================================================
# ê²½ë¡œ ì„¤ì •
# ============================================================
BASE_DIR = Path(__file__).parent
STATE_FILE = BASE_DIR / "output" / "state.json"
OUTPUT_DIR = BASE_DIR / "output"
ASSETS_DIR = BASE_DIR / "assets"
BGM_DIR = BASE_DIR / "BGM"
TRANSITION_ASSETS_DIR = BASE_DIR / "Transition"

# ì¶œë ¥ ë””ë ‰í† ë¦¬ (CLAUDE.md êµ¬ì¡°ì— ë§ì¶¤)
SCRIPTS_DIR = OUTPUT_DIR / "1_scripts"
AUDIO_DIR = OUTPUT_DIR / "2_audio"
BACKGROUNDS_DIR = OUTPUT_DIR / "3_backgrounds"
IMAGES_DIR = OUTPUT_DIR / "3_images"
VISUAL_DIR = OUTPUT_DIR / "4_visual"
RENDERS_DIR = OUTPUT_DIR / "5_renders"
COMPOSITE_DIR = OUTPUT_DIR / "6_scenes"      # ë°°ê²½ í•©ì„±ëœ ì”¬
SCENES_DIR = OUTPUT_DIR / "1_scripts"        # scenes.json ìœ„ì¹˜
SECTIONS_DIR = OUTPUT_DIR / "6_sections"
TRANSITIONS_DIR = OUTPUT_DIR / "7_transitions"

# Remotion ë””ë ‰í† ë¦¬
REMOTION_DIR = BASE_DIR / "remotion"
REMOTION_SCENES_DIR = REMOTION_DIR / "src" / "scenes"
REMOTION_TRANSITIONS_DIR = REMOTION_DIR / "src" / "transitions"
REMOTION_ASSETS_DIR = REMOTION_DIR / "public" / "assets"

# ============================================================
# ì„¹ì…˜ ì •ë³´ ë™ì  ë¡œë“œ
# ============================================================
# ì„¹ì…˜ ì •ë³´ëŠ” reading_script.json ë˜ëŠ” scenes.jsonì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ
# í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’ì€ íŒŒì¼ì´ ì—†ì„ ë•Œë§Œ ì‚¬ìš©

def get_sections() -> List[str]:
    """
    ì„¹ì…˜ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ë¡œë“œ
    ìš°ì„ ìˆœìœ„: scenes.json > reading_script.json > ê¸°ë³¸ê°’
    """
    # 1. scenes.jsonì—ì„œ ë¡œë“œ (ê°€ì¥ ì •í™•)
    scenes_path = SCRIPTS_DIR / "scenes.json"
    if scenes_path.exists():
        try:
            with open(scenes_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                sections_info = data.get("meta", {}).get("sections", {})
                if sections_info:
                    # ì„¹ì…˜ ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ scenes ë°°ì—´ì—ì„œ ìˆœì„œ ì¶”ì¶œ
                    seen = []
                    for scene in data.get("scenes", []):
                        section = scene.get("section")
                        if section and section not in seen:
                            seen.append(section)
                    if seen:
                        return seen
        except Exception as e:
            print(f"[WARN] Failed to load scenes.json: {e}")

    # 2. reading_script.jsonì—ì„œ ë¡œë“œ
    script_path = SCRIPTS_DIR / "reading_script.json"
    if script_path.exists():
        try:
            with open(script_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                sections = [s["id"] for s in data.get("sections", [])]
                if sections:
                    return sections
        except Exception as e:
            print(f"[WARN] Failed to load reading_script.json: {e}")

    # 3. ê¸°ë³¸ê°’ (fallback)
    print("[WARN] Using default sections - no script files found")
    return ["hook", "background", "core1", "core2", "core3", "insight", "outro"]


def get_section_scenes(section: str) -> List[str]:
    """íŠ¹ì • ì„¹ì…˜ì˜ ì”¬ ID ëª©ë¡ ë°˜í™˜"""
    scenes_path = SCRIPTS_DIR / "scenes.json"
    if scenes_path.exists():
        try:
            with open(scenes_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                sections_info = data.get("meta", {}).get("sections", {})
                return sections_info.get(section, {}).get("scenes", [])
        except:
            pass
    return []


def get_all_scenes() -> List[str]:
    """ëª¨ë“  ì”¬ ID ëª©ë¡ ë°˜í™˜ (ìˆœì„œëŒ€ë¡œ)"""
    scenes_path = SCRIPTS_DIR / "scenes.json"
    if scenes_path.exists():
        try:
            with open(scenes_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return [s["scene_id"] for s in data.get("scenes", [])]
        except:
            pass
    return []


def validate_parts_info() -> Dict[str, Any]:
    """
    state.jsonì˜ parts ì •ë³´ë¥¼ ê²€ì¦í•˜ê³  ë¬¸ì œì  ë°˜í™˜

    Returns:
        {
            "valid": bool,
            "errors": List[str],
            "warnings": List[str],
            "parts_info": Dict (ìœ íš¨í•œ ê²½ìš°)
        }
    """
    result = {"valid": True, "errors": [], "warnings": [], "parts_info": None}

    state = load_state()
    sections_info = state.get("sections", {})

    if not sections_info:
        result["valid"] = False
        result["errors"].append("state.jsonì— sections ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. scene-director ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return result

    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ["all", "parts", "part_scenes"]
    for field in required_fields:
        if field not in sections_info:
            result["valid"] = False
            result["errors"].append(f"sections.{field} í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    if not result["valid"]:
        return result

    all_sections = sections_info.get("all", [])
    parts = sections_info.get("parts", {})
    part_scenes = sections_info.get("part_scenes", {})
    max_scenes = sections_info.get("max_scenes_per_part", 10)

    # Partì™€ part_scenes í‚¤ ì¼ì¹˜ í™•ì¸
    if set(parts.keys()) != set(part_scenes.keys()):
        result["valid"] = False
        result["errors"].append("partsì™€ part_scenesì˜ í‚¤ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ê° Partì˜ ì”¬ ê°œìˆ˜ í™•ì¸
    for part_name, scenes in part_scenes.items():
        if len(scenes) > max_scenes:
            result["warnings"].append(f"{part_name}: {len(scenes)}ê°œ ì”¬ (ìµœëŒ€ {max_scenes}ê°œ ê¶Œì¥ ì´ˆê³¼)")

        # ì”¬ íŒŒì¼ ì¡´ì¬ í™•ì¸
        for scene_id in scenes:
            scene_file = SCRIPTS_DIR / f"{scene_id}.json"
            if not scene_file.exists():
                result["errors"].append(f"{scene_id}.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                result["valid"] = False

    # ëª¨ë“  ì„¹ì…˜ì´ partsì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    sections_in_parts = []
    for sections_list in parts.values():
        sections_in_parts.extend(sections_list)

    missing_sections = set(all_sections) - set(sections_in_parts)
    if missing_sections:
        result["valid"] = False
        result["errors"].append(f"partsì— ëˆ„ë½ëœ ì„¹ì…˜: {missing_sections}")

    extra_sections = set(sections_in_parts) - set(all_sections)
    if extra_sections:
        result["warnings"].append(f"allì— ì—†ëŠ” ì„¹ì…˜ì´ partsì— í¬í•¨ë¨: {extra_sections}")

    if result["valid"]:
        result["parts_info"] = {
            "total_parts": len(parts),
            "total_scenes": sum(len(s) for s in part_scenes.values()),
            "parts": parts,
            "part_scenes": part_scenes
        }

    return result


def cmd_validate_parts(args):
    """Part ë¶„í•  ì •ë³´ ê²€ì¦"""
    print("\n[VALIDATE] Part ë¶„í•  ì •ë³´ ê²€ì¦")
    print("=" * 50)

    result = validate_parts_info()

    if result["errors"]:
        print("\nâŒ ì˜¤ë¥˜:")
        for err in result["errors"]:
            print(f"  - {err}")

    if result["warnings"]:
        print("\nâš ï¸ ê²½ê³ :")
        for warn in result["warnings"]:
            print(f"  - {warn}")

    if result["valid"]:
        info = result["parts_info"]
        print(f"\nâœ… ê²€ì¦ í†µê³¼")
        print(f"  - ì´ Part: {info['total_parts']}ê°œ")
        print(f"  - ì´ ì”¬: {info['total_scenes']}ê°œ")
        print("\nğŸ“‹ Part êµ¬ì„±:")
        for part_name, sections in info["parts"].items():
            scenes = info["part_scenes"][part_name]
            print(f"  {part_name}: {sections} ({len(scenes)}ê°œ ì”¬)")
    else:
        print("\nâŒ ê²€ì¦ ì‹¤íŒ¨. scene-director ì—ì´ì „íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

    return result["valid"]


# ì „ì—­ ë³€ìˆ˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œë¡œ ëŒ€ì²´ (lazy loading)
# ì‚¬ìš©ì²˜ì—ì„œ get_sections() í˜¸ì¶œ
SECTIONS = None  # Deprecated: use get_sections() instead


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================
def load_json(path: Path) -> Optional[Dict]:
    """JSON íŒŒì¼ ë¡œë“œ"""
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def save_json(path: Path, data: Dict, silent: bool = False):
    """JSON íŒŒì¼ ì €ì¥"""
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    if not silent:
        print(f"[OK] Saved: {path}")


def load_state() -> Dict:
    """state.json ë¡œë“œ"""
    if STATE_FILE.exists():
        return load_json(STATE_FILE)
    return {
        "project_id": None,
        "category": None,
        "topic": None,
        "phase": "initialized",
        "current_step": 0,
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }


def save_state(state: Dict):
    """state.json ì €ì¥"""
    state["updated_at"] = datetime.now().isoformat()
    save_json(STATE_FILE, state)


def ensure_dirs():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    dirs = [
        SCRIPTS_DIR,
        AUDIO_DIR,
        BACKGROUNDS_DIR,
        IMAGES_DIR,
        VISUAL_DIR,
        RENDERS_DIR,
        SCENES_DIR,
        SECTIONS_DIR,
        TRANSITIONS_DIR,
        REMOTION_SCENES_DIR,
        REMOTION_TRANSITIONS_DIR,
    ]
    for d in dirs:
        d.mkdir(parents=True, exist_ok=True)


def get_scenes_for_section(section: str) -> List[str]:
    """íŠ¹ì • ì„¹ì…˜ì˜ ì”¬ ëª©ë¡ ë°˜í™˜"""
    scenes_file = SCRIPTS_DIR / "scenes.json"
    if not scenes_file.exists():
        print(f"[ERROR] scenes.json ì—†ìŒ")
        return []

    scenes_data = load_json(scenes_file)
    if not scenes_data or "meta" not in scenes_data:
        return []

    section_info = scenes_data["meta"]["sections"].get(section, {})
    return section_info.get("scenes", [])


# ============================================================
# Phase 2: STRUCTURE (merge-scenes)
# ============================================================
def cmd_merge_scenes(args):
    """ì”¬ íŒŒì¼ ë³‘í•© (scenes_*.json -> scenes.json + s#.json)"""
    print("\n[MERGE] Scene files merging...")

    # ë³‘í•©í•  íŒŒì¼ ì°¾ê¸°
    section_files = {
        "hook": SCRIPTS_DIR / "scenes_hook.json",
        "background": None,  # hook íŒŒì¼ì— í¬í•¨
        "core1": SCRIPTS_DIR / "scenes_core1.json",
        "core2": SCRIPTS_DIR / "scenes_core2.json",
        "core3": SCRIPTS_DIR / "scenes_core3.json",
        "insight": None,  # outro íŒŒì¼ì— í¬í•¨
        "outro": SCRIPTS_DIR / "scenes_outro.json",
    }

    all_scenes = []
    all_backgrounds = []
    section_scene_map = {}

    # ê° íŒŒì¼ì—ì„œ ì”¬ ìˆ˜ì§‘
    for section, file_path in section_files.items():
        if file_path and file_path.exists():
            data = load_json(file_path)
            if data and "scenes" in data:
                for scene in data["scenes"]:
                    all_scenes.append(scene)
                    sec = scene.get("section", section)
                    if sec not in section_scene_map:
                        section_scene_map[sec] = []
                    section_scene_map[sec].append(scene["scene_id"])

            if data and "backgrounds" in data:
                all_backgrounds.extend(data["backgrounds"])

    if not all_scenes:
        print("[ERROR] No scenes to merge.")
        return

    # ì„¹ì…˜ ìˆœì„œëŒ€ë¡œ ì”¬ ì •ë ¬ ë° ID ì¬ë¶€ì—¬
    section_order = ["hook", "background", "core1", "core2", "core3", "insight", "outro"]
    sorted_scenes_data = []
    new_section_map = {}
    scene_counter = 1

    for section in section_order:
        section_scenes = [s for s in all_scenes if s.get("section") == section]
        if not section_scenes:
            continue

        new_section_map[section] = {"scenes": [], "count": 0}

        for scene in section_scenes:
            new_scene_id = f"s{scene_counter}"
            scene["scene_id"] = new_scene_id
            new_section_map[section]["scenes"].append(new_scene_id)
            new_section_map[section]["count"] += 1
            sorted_scenes_data.append(scene)
            scene_counter += 1

    # ì”¬ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ê°œë³„ íŒŒì¼ ì €ì¥
    sorted_scenes = []
    for scene in sorted_scenes_data:
        new_id = scene["scene_id"]

        # ê°œë³„ ì”¬ íŒŒì¼ ì €ì¥
        scene_file = SCRIPTS_DIR / f"{new_id}.json"
        save_json(scene_file, scene, silent=True)

        # scenes.jsonìš© ìš”ì•½ ë°ì´í„°
        sorted_scenes.append({
            "scene_id": new_id,
            "section": scene.get("section"),
            "narration_preview": scene.get("narration_tts", "")[:30] + "...",
            "bg_id": scene.get("bg_id")
        })

    # scenes.json ìƒì„±
    scenes_json = {
        "meta": {
            "total_scenes": len(sorted_scenes),
            "duration_target": 300,
            "sections": new_section_map
        },
        "scenes": sorted_scenes,
        "backgrounds": all_backgrounds
    }

    save_json(SCRIPTS_DIR / "scenes.json", scenes_json)

    # bg_prompts.json ìƒì„± (ë°°ê²½ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ)
    bg_prompts = {}
    for scene in all_scenes:
        bg_id = scene.get("bg_id")
        bg_prompt = scene.get("bg_prompt")
        if bg_id and bg_prompt and bg_id not in bg_prompts:
            bg_prompts[bg_id] = {
                "bg_id": bg_id,
                "prompt": bg_prompt,
                "scenes": []
            }
        if bg_id in bg_prompts:
            bg_prompts[bg_id]["scenes"].append(scene["scene_id"])

    save_json(SCRIPTS_DIR / "bg_prompts.json", {"backgrounds": list(bg_prompts.values())})

    # scenes_minimal.json ìƒì„± (ì—ì´ì „íŠ¸ìš© ê²½ëŸ‰ ë°ì´í„°)
    minimal_scenes = []
    for scene in all_scenes:
        minimal_scenes.append({
            "scene_id": scene["scene_id"],
            "section": scene.get("section"),
            "subtitle_display": scene.get("subtitle_display", "")
        })

    save_json(SCRIPTS_DIR / "scenes_minimal.json", {"scenes": minimal_scenes})

    print(f"\n[DONE] Scene merge completed!")
    print(f"  - Total {len(sorted_scenes)} scenes")
    print(f"  - scenes.json created")
    print(f"  - s1.json ~ s{len(sorted_scenes)}.json created")
    print(f"  - bg_prompts.json created ({len(bg_prompts)} backgrounds)")
    print(f"  - scenes_minimal.json created")

    # state.json ì—…ë°ì´íŠ¸
    state = load_state()
    state["phase"] = "scenes_completed"
    state["current_step"] = 4
    state["scenes_count"] = len(sorted_scenes)
    save_state(state)


# ============================================================
# Phase 3: AUDIO
# ============================================================
def cmd_audio(args):
    """TTS ìƒì„± + Whisper íƒ€ì„ìŠ¤íƒ¬í”„"""
    if not OPENAI_AVAILABLE:
        print("[ERROR] OpenAI íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openai")
        return

    voice = args.voice
    print(f"\n[TTS] Starting TTS generation (voice: {voice})")

    # scenes.jsonì—ì„œ ì„¹ì…˜ë³„ narration ìˆ˜ì§‘
    scenes_file = SCRIPTS_DIR / "scenes.json"
    if not scenes_file.exists():
        print("[ERROR] scenes.json not found. Run Phase 2 first.")
        return

    scenes_data = load_json(scenes_file)

    # ì„¹ì…˜ë³„ ì²˜ë¦¬
    sections = get_sections()
    for section in sections:
        scene_ids = get_scenes_for_section(section)
        if not scene_ids:
            print(f"[SKIP] {section} section has no scenes")
            continue

        # ì„¹ì…˜ì˜ ëª¨ë“  narration_tts ìˆ˜ì§‘
        narration_parts = []
        for scene_id in scene_ids:
            scene_file = SCRIPTS_DIR / f"{scene_id}.json"
            if scene_file.exists():
                scene_data = load_json(scene_file)
                if scene_data and "narration_tts" in scene_data:
                    narration_parts.append(scene_data["narration_tts"])

        if not narration_parts:
            print(f"[SKIP] {section} section has no narration")
            continue

        full_narration = " ".join(narration_parts)

        # TTS ìƒì„±
        audio_path = AUDIO_DIR / f"{section}.mp3"
        if audio_path.exists() and not args.force:
            print(f"[SKIP] {section}.mp3 already exists (use --force to regenerate)")
            continue

        print(f"[TTS] Generating {section} audio... ({len(full_narration)} chars)")
        generate_tts(full_narration, audio_path, voice)

        # Whisper íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
        whisper_path = AUDIO_DIR / f"{section}_whisper.json"
        print(f"[WHISPER] Extracting timestamps for {section}...")
        extract_whisper_timestamps(audio_path, whisper_path)

    print("\n[DONE] Phase 3 (AUDIO) completed!")
    print("Next: Run 'python pipeline.py srt-timing' for subtitle timing")


def generate_tts(text: str, output_path: Path, voice: str = "nova"):
    """OpenAI TTSë¡œ ìŒì„± ìƒì„±"""
    client = OpenAI()

    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²­í¬ ë¶„í•  (4096ì ì œí•œ)
    max_chars = 4000
    if len(text) <= max_chars:
        response = client.audio.speech.create(
            model="tts-1-hd",
            voice=voice,
            input=text
        )
        response.stream_to_file(str(output_path))
    else:
        # ì²­í¬ ë¶„í•  ë° ë³‘í•© (ffmpeg ì‚¬ìš©)
        import tempfile
        chunks = []
        for i in range(0, len(text), max_chars):
            chunk = text[i:i+max_chars]
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸° ì‹œë„
            if i + max_chars < len(text):
                last_period = chunk.rfind("...")
                if last_period > max_chars // 2:
                    chunk = chunk[:last_period + 3]
            chunks.append(chunk)

        temp_files = []
        with tempfile.TemporaryDirectory() as tmpdir:
            for idx, chunk in enumerate(chunks):
                temp_path = Path(tmpdir) / f"chunk_{idx}.mp3"
                response = client.audio.speech.create(
                    model="tts-1-hd",
                    voice=voice,
                    input=chunk
                )
                response.stream_to_file(str(temp_path))
                temp_files.append(temp_path)

            # ffmpegë¡œ ë³‘í•©
            list_file = Path(tmpdir) / "list.txt"
            with open(list_file, 'w') as f:
                for tf in temp_files:
                    f.write(f"file '{tf}'\n")

            subprocess.run([
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", str(list_file), "-c", "copy", str(output_path)
            ], capture_output=True)

    print(f"  [OK] {output_path.name}")


def extract_whisper_timestamps(audio_path: Path, output_path: Path):
    """Whisperë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
    client = OpenAI()

    with open(audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="verbose_json",
            timestamp_granularities=["word"]
        )

    result = {
        "text": transcript.text,
        "words": [
            {"word": w.word, "start": w.start, "end": w.end}
            for w in transcript.words
        ] if transcript.words else []
    }

    save_json(output_path, result)


def cmd_srt_timing(args):
    """SRT íƒ€ì´ë° ìƒì„± (subtitle_display + Whisper ë§¤ì¹­)"""
    print("\n[SRT] Generating timing files...")

    scenes_file = SCRIPTS_DIR / "scenes.json"
    if not scenes_file.exists():
        print("[ERROR] scenes.json not found")
        return

    scenes_data = load_json(scenes_file)

    # ì„¹ì…˜ë³„ ì²˜ë¦¬
    sections = get_sections()
    for section in sections:
        section_scenes = scenes_data["meta"]["sections"].get(section, {}).get("scenes", [])
        if not section_scenes:
            continue

        whisper_file = AUDIO_DIR / f"{section}_whisper.json"
        if not whisper_file.exists():
            print(f"[SKIP] {section}_whisper.json not found")
            continue

        whisper_data = load_json(whisper_file)
        words = whisper_data.get("words", [])

        if not words:
            print(f"[SKIP] {section} has no words")
            continue

        # ì„¹ì…˜ ì „ì²´ duration ê³„ì‚°
        section_duration = words[-1]["end"] if words else 0

        # ì”¬ë³„ ìë§‰ ë¶„í• 
        scene_offset = 0.0

        for scene_id in section_scenes:
            scene_file = SCRIPTS_DIR / f"{scene_id}.json"
            if not scene_file.exists():
                continue

            scene_data = load_json(scene_file)
            subtitle_display = scene_data.get("subtitle_display", "")

            if not subtitle_display:
                continue

            # ìë§‰ ë¶„í•  (;; êµ¬ë¶„ì)
            subtitle_segments = subtitle_display.split(";;")
            num_segments = len(subtitle_segments)

            if num_segments == 0:
                continue

            # ì´ ì”¬ì˜ ì˜ˆìƒ duration (ì„¹ì…˜ durationì„ ì”¬ ê°œìˆ˜ë¡œ ê· ë“± ë¶„í• )
            scene_duration = section_duration / len(section_scenes)
            segment_duration = scene_duration / num_segments

            # íƒ€ì´ë° íŒŒì¼ ìƒì„±
            timing_data = {
                "scene_id": scene_id,
                "section": section,
                "duration": scene_duration,
                "section_start": scene_offset,
                "section_end": scene_offset + scene_duration,
                "subtitle_segments": []
            }

            for idx, text in enumerate(subtitle_segments):
                segment_start = scene_offset + (idx * segment_duration)
                segment_end = scene_offset + ((idx + 1) * segment_duration)

                timing_data["subtitle_segments"].append({
                    "index": idx + 1,
                    "text": text.strip(),
                    "start": round(segment_start, 2),
                    "end": round(segment_end, 2),
                    "duration": round(segment_duration, 2)
                })

            # s#_timed.json ì €ì¥
            timing_file = AUDIO_DIR / f"{scene_id}_timed.json"
            save_json(timing_file, timing_data, silent=True)

            # SRT íŒŒì¼ ìƒì„±
            srt_content = generate_srt(timing_data["subtitle_segments"])
            srt_file = AUDIO_DIR / f"{scene_id}.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write(srt_content)

            scene_offset += scene_duration

        print(f"[OK] {section}: {len(section_scenes)} scenes processed")

    print("\n[DONE] SRT timing completed!")


def generate_srt(segments: List[Dict]) -> str:
    """SRT íŒŒì¼ ë‚´ìš© ìƒì„±"""
    srt_lines = []

    for seg in segments:
        idx = seg["index"]
        start = format_srt_time(seg["start"])
        end = format_srt_time(seg["end"])
        text = seg["text"]

        srt_lines.append(f"{idx}")
        srt_lines.append(f"{start} --> {end}")
        srt_lines.append(text)
        srt_lines.append("")

    return "\n".join(srt_lines)


def format_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (00:00:00,000)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


# ============================================================
# Phase 4: CODE (update-root)
# ============================================================
def cmd_update_root(args):
    """Root.tsx ìë™ ì—…ë°ì´íŠ¸"""
    print("\n[ROOT] Root.tsx auto update")

    # ì”¬ ì»´í¬ë„ŒíŠ¸ ìŠ¤ìº”
    scene_files = sorted(REMOTION_SCENES_DIR.glob("S*.tsx"))
    transition_files = sorted(REMOTION_TRANSITIONS_DIR.glob("T*.tsx"))

    if not scene_files:
        print("[ERROR] ì”¬ íŒŒì¼ ì—†ìŒ (remotion/src/scenes/S*.tsx)")
        return

    # ê° ì”¬ì˜ duration ê³„ì‚°
    compositions = []

    for scene_file in scene_files:
        scene_id = scene_file.stem.lower()  # S1 -> s1
        timing_file = AUDIO_DIR / f"{scene_id}_timed.json"

        if timing_file.exists():
            timing_data = load_json(timing_file)
            # s{n}_timed.json êµ¬ì¡°ì—ì„œ duration ê°€ì ¸ì˜¤ê¸°
            duration = timing_data.get("timing", {}).get("duration", timing_data.get("duration", 10))
        else:
            duration = 10  # default

        duration_frames = int(duration * 30) + 1
        compositions.append({
            "id": scene_file.stem,
            "component": scene_file.stem,
            "durationInFrames": duration_frames,
            "type": "scene"
        })

    for trans_file in transition_files:
        compositions.append({
            "id": trans_file.stem,
            "component": trans_file.stem,
            "durationInFrames": 90,  # 3ì´ˆ ê¸°ë³¸
            "type": "transition"
        })

    # Root.tsx ìƒì„±
    root_content = generate_root_tsx(compositions)
    root_path = REMOTION_DIR / "src" / "Root.tsx"

    with open(root_path, 'w', encoding='utf-8') as f:
        f.write(root_content)

    print(f"[OK] Root.tsx ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(compositions)}ê°œ Composition)")


def generate_root_tsx(compositions: List[Dict]) -> str:
    """Root.tsx ë‚´ìš© ìƒì„±"""
    # imports
    scene_imports = []
    trans_imports = []

    for comp in compositions:
        if comp["type"] == "scene":
            scene_imports.append(f'import {{ {comp["component"]} }} from "./scenes/{comp["component"]}";')
        else:
            trans_imports.append(f'import {{ {comp["component"]} }} from "./transitions/{comp["component"]}";')

    imports = "\n".join(scene_imports + trans_imports)

    # compositions
    comp_elements = []
    for comp in compositions:
        comp_elements.append(
            f'      <Composition\n'
            f'        id="{comp["id"]}"\n'
            f'        component={{{comp["component"]}}}\n'
            f'        durationInFrames={{{comp["durationInFrames"]}}}\n'
            f'        fps={{30}}\n'
            f'        width={{1920}}\n'
            f'        height={{1080}}\n'
            f'      />'
        )

    comp_str = "\n".join(comp_elements)

    return f'''import React from "react";
import {{ Composition }} from "remotion";
{imports}

export const RemotionRoot: React.FC = () => {{
  return (
    <>
{comp_str}
    </>
  );
}};
'''


# ============================================================
# Phase 5: RENDER
# ============================================================
def cmd_render(args):
    """Remotion ë Œë”ë§ (ë°°ê²½ í¬í•¨ ê¸°ë³¸, --transparentë¡œ íˆ¬ëª… ë Œë”ë§)"""
    transparent = args.transparent
    mode = "íˆ¬ëª… ë°°ê²½" if transparent else "ë°°ê²½ í¬í•¨"
    print(f"\nğŸ¬ Remotion ë Œë”ë§ ì‹œì‘ ({mode})")

    section = args.section
    scene = args.scene
    concurrency = args.concurrency

    if scene:
        # ë‹¨ì¼ ì”¬ ë Œë”ë§
        render_scene(scene, concurrency, transparent)
    elif section:
        # ì„¹ì…˜ë³„ ë Œë”ë§
        scene_ids = get_scenes_for_section(section)
        for scene_id in scene_ids:
            render_scene(scene_id, concurrency, transparent)
        # ì „í™˜ í´ë¦½ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì„¹ì…˜ ì§ì ‘ ì—°ê²°)
    else:
        # ì „ì²´ ë Œë”ë§
        scenes_data = load_json(SCENES_DIR / "scenes.json")
        if scenes_data:
            for scene_info in scenes_data.get("scenes", []):
                render_scene(scene_info["scene_id"], concurrency, transparent)

        # ì „í™˜ì€ ì„¹ì…˜ ê°„ ì—°ê²°ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì§ì ‘ ì—°ê²°)

    print("\n[OK] ë Œë”ë§ ì™„ë£Œ!")
    if not transparent:
        print("ğŸ’¡ ë°°ê²½ í¬í•¨ ë Œë”ë§ ì™„ë£Œ. composite ë‹¨ê³„ë¥¼ ìƒëµí•˜ê³  section-mergeë¡œ ì§„í–‰í•˜ì„¸ìš”.")


def render_scene(scene_id: str, concurrency: int = 4, transparent: bool = False):
    """ë‹¨ì¼ ì”¬ ë Œë”ë§

    Args:
        scene_id: ì”¬ ID (ì˜ˆ: s1)
        concurrency: ë™ì‹œ ë Œë”ë§ ìˆ˜
        transparent: Trueë©´ íˆ¬ëª… ë°°ê²½ WebM, Falseë©´ ë°°ê²½ í¬í•¨ MP4
    """
    comp_id = scene_id.upper() if not scene_id[0].isupper() else scene_id  # s1 -> S1

    if transparent:
        # íˆ¬ëª… ë°°ê²½ ëª¨ë“œ: WebM (ì•ŒíŒŒ ì±„ë„ í¬í•¨)
        output_path = RENDERS_DIR / f"{scene_id.lower()}_raw.webm"

        if output_path.exists():
            print(f"[SKIP] {scene_id} ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ")
            return

        print(f"ğŸ¬ {scene_id} ë Œë”ë§ ì¤‘... (íˆ¬ëª…)")

        # âš ï¸ ì¤‘ìš”: --pixel-format yuva420p í•„ìˆ˜! (ì•ŒíŒŒ ì±„ë„ í¬í•¨)
        cmd = f'npx remotion render src/index.ts {comp_id} --output "{output_path}" --codec vp9 --image-format png --pixel-format yuva420p --concurrency {concurrency}'
    else:
        # ë°°ê²½ í¬í•¨ ëª¨ë“œ: MP4 (ì§ì ‘ ì¶œë ¥)
        output_path = COMPOSITE_DIR / f"{scene_id.lower()}.mp4"

        if output_path.exists():
            print(f"[SKIP] {scene_id} ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ")
            return

        print(f"ğŸ¬ {scene_id} ë Œë”ë§ ì¤‘... (ë°°ê²½ í¬í•¨)")

        # ë°°ê²½ í¬í•¨ ë Œë”ë§: H.264 MP4
        cmd = f'npx remotion render src/index.ts {comp_id} --output "{output_path}" --codec h264 --image-format jpeg --crf 18 --concurrency {concurrency}'

    result = subprocess.run(cmd, cwd=str(REMOTION_DIR), capture_output=True, text=True, shell=True)

    if result.returncode == 0:
        print(f"  [OK] {output_path.name}")
    else:
        print(f"  [ERROR] ì‹¤íŒ¨: {result.stderr[:500]}")


# ì „í™˜ í´ë¦½ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì„¹ì…˜ ì§ì ‘ ì—°ê²°)
# def render_transition(trans_id: str, concurrency: int = 4):
#     """ì „í™˜ ë Œë”ë§ (ì‚¬ìš© ì•ˆí•¨)"""
#     pass


def cmd_composite(args):
    """FFmpeg ë°°ê²½ í•©ì„± (2-layer) - íˆ¬ëª… ë Œë”ë§ ì‹œì—ë§Œ í•„ìš”"""
    print("\nğŸ¨ ë°°ê²½ í•©ì„± ì‹œì‘")
    print("ğŸ’¡ ì°¸ê³ : ë°°ê²½ í¬í•¨ ë Œë”ë§(ê¸°ë³¸)ì„ ì‚¬ìš©í•œ ê²½ìš° ì´ ë‹¨ê³„ëŠ” ìƒëµë©ë‹ˆë‹¤.")

    section = args.section

    if section:
        scene_ids = get_scenes_for_section(section)
    else:
        scenes_data = load_json(SCENES_DIR / "scenes.json")
        scene_ids = [s["scene_id"] for s in scenes_data.get("scenes", [])]

    for scene_id in scene_ids:
        composite_scene(scene_id)

    print("\n[OK] ë°°ê²½ í•©ì„± ì™„ë£Œ!")


def composite_scene(scene_id: str):
    """ë‹¨ì¼ ì”¬ ë°°ê²½ í•©ì„± (WebM íˆ¬ëª… + ë°°ê²½ PNG â†’ MP4)"""
    render_path = RENDERS_DIR / f"{scene_id.lower()}_raw.webm"
    bg_path = BACKGROUNDS_DIR / f"bg_{scene_id.lower()}.png"
    output_path = COMPOSITE_DIR / f"{scene_id.lower()}.mp4"

    if not render_path.exists():
        print(f"[WARN] {scene_id} ë Œë”ë§ ì—†ìŒ, ìŠ¤í‚µ")
        return

    if output_path.exists():
        print(f"[SKIP] {scene_id} í•©ì„±ë³¸ ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ")
        return

    print(f"ğŸ¨ {scene_id} ë°°ê²½ í•©ì„± ì¤‘...")

    # ë¨¼ì € ë Œë”ë§ ì˜ìƒì˜ ê¸¸ì´ë¥¼ êµ¬í•¨
    duration_cmd = f'ffprobe -v error -show_entries format=duration -of csv=p=0 "{render_path}"'
    duration_result = subprocess.run(duration_cmd, capture_output=True, text=True, shell=True)
    duration = float(duration_result.stdout.strip()) if duration_result.stdout.strip() else 10.0

    if bg_path.exists():
        # âš ï¸ ì¤‘ìš”: -c:v libvpx-vp9 ë””ì½”ë”ì™€ format=yuva420p í•„ìˆ˜!
        # Remotionì—ì„œ yuva420pë¡œ ë Œë”ë§í•œ WebMì˜ ì•ŒíŒŒì±„ë„ì„ ì œëŒ€ë¡œ ì½ìœ¼ë ¤ë©´
        # libvpx-vp9 ë””ì½”ë”ë¥¼ ëª…ì‹œí•˜ê³  yuva420p í¬ë§·ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨
        # ì´ ì„¤ì • ì—†ìœ¼ë©´ ë°°ê²½ì´ ì²« í”„ë ˆì„ë§Œ í‘œì‹œë˜ëŠ” ë¬¸ì œ ë°œìƒ
        cmd = f'ffmpeg -y -loop 1 -t {duration} -framerate 30 -i "{bg_path}" -c:v libvpx-vp9 -i "{render_path}" -filter_complex "[1:v]format=yuva420p[fg];[0:v]scale=1920:1080,format=yuva420p[bg];[bg][fg]overlay=0:0" -c:v libx264 -preset fast -pix_fmt yuv420p -t {duration} "{output_path}"'
    else:
        # ë°°ê²½ ì—†ìŒ: ê²€ì€ ë°°ê²½ ì‚¬ìš©
        print(f"  [WARN] {bg_path.name} ì—†ìŒ, ê²€ì€ ë°°ê²½ ì‚¬ìš©")
        cmd = f'ffmpeg -y -f lavfi -t {duration} -i "color=c=black:s=1920x1080:r=30" -c:v libvpx-vp9 -i "{render_path}" -filter_complex "[1:v]format=yuva420p[fg];[0:v]format=yuva420p[bg];[bg][fg]overlay=0:0" -c:v libx264 -preset fast -pix_fmt yuv420p -t {duration} "{output_path}"'

    result = subprocess.run(cmd, capture_output=True, text=True, shell=True)

    if result.returncode == 0:
        print(f"  [OK] {output_path.name}")
    else:
        print(f"  [ERROR] ì‹¤íŒ¨: {result.stderr[:200]}")


def cmd_section_merge(args):
    """ì„¹ì…˜ í•©ì„± (concat + audio)"""
    print("\nğŸ”— ì„¹ì…˜ í•©ì„± ì‹œì‘")

    section = args.section
    sections_to_process = [section] if section else get_sections()

    for sec in sections_to_process:
        merge_section(sec)

    print("\n[OK] ì„¹ì…˜ í•©ì„± ì™„ë£Œ!")


def merge_section(section: str):
    """ë‹¨ì¼ ì„¹ì…˜ í•©ì„± (ì”¬ ì‚¬ì´ gapì„ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì±„ì›€)"""
    scene_ids = get_scenes_for_section(section)
    if not scene_ids:
        print(f"[WARN] {section} ì„¹ì…˜ì— ì”¬ ì—†ìŒ, ìŠ¤í‚µ")
        return

    output_path = SECTIONS_DIR / f"section_{section}.mp4"
    audio_path = AUDIO_DIR / f"{section}.mp3"

    if output_path.exists():
        print(f"[SKIP] section_{section}.mp4 ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ")
        return

    print(f"ğŸ”— {section} ì„¹ì…˜ í•©ì„± ì¤‘...")

    # ì”¬ë³„ íƒ€ì´ë° ì •ë³´ ë¡œë“œ ë° gap ê³„ì‚°
    import tempfile
    padded_files = []
    temp_files = []  # ì‚­ì œí•  ì„ì‹œ íŒŒì¼ ëª©ë¡

    for i, scene_id in enumerate(scene_ids):
        scene_path = COMPOSITE_DIR / f"{scene_id}.mp4"
        if not scene_path.exists():
            print(f"  [WARN] {scene_id}.mp4 ì—†ìŒ, ìŠ¤í‚µ")
            continue

        # í˜„ì¬ ì”¬ì˜ íƒ€ì´ë° ì •ë³´
        timed_path = AUDIO_DIR / f"{scene_id}_timed.json"
        if not timed_path.exists():
            padded_files.append(scene_path)
            continue

        current_timing = load_json(timed_path)
        current_end = current_timing.get('timing', {}).get('scene_end', 0)

        # ë‹¤ìŒ ì”¬ì˜ ì‹œì‘ ì‹œê°„ í™•ì¸ (gap ê³„ì‚°)
        gap_duration = 0
        if i + 1 < len(scene_ids):
            next_scene_id = scene_ids[i + 1]
            next_timed_path = AUDIO_DIR / f"{next_scene_id}_timed.json"
            if next_timed_path.exists():
                next_timing = load_json(next_timed_path)
                next_start = next_timing.get('timing', {}).get('scene_start', 0)
                gap_duration = next_start - current_end

        # gapì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥
        if gap_duration > 0.05:  # 50ms ì´ìƒì¸ ê²½ìš°ë§Œ
            padded_path = COMPOSITE_DIR / f"{scene_id}_padded.mp4"
            pad_cmd = f'ffmpeg -y -i "{scene_path}" -vf "tpad=stop_mode=clone:stop_duration={gap_duration}" -c:v libx264 -preset fast -an "{padded_path}"'
            result = subprocess.run(pad_cmd, capture_output=True, text=True, shell=True)
            if result.returncode == 0:
                padded_files.append(padded_path)
                temp_files.append(padded_path)
                print(f"    {scene_id}: +{gap_duration:.2f}s gap ì¶”ê°€")
            else:
                padded_files.append(scene_path)
        else:
            padded_files.append(scene_path)

    if not padded_files:
        print(f"  [ERROR] {section} ì„¹ì…˜ì— í•©ì„± ê°€ëŠ¥í•œ ì”¬ ì—†ìŒ")
        return

    # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for sf in padded_files:
            f.write(f"file '{sf}'\n")
        list_file = f.name

    try:
        if audio_path.exists():
            # ì˜ìƒ concat + ì˜¤ë””ì˜¤ í•©ì„±
            cmd = f'ffmpeg -y -f concat -safe 0 -i "{list_file}" -i "{audio_path}" -c:v libx264 -preset fast -c:a aac -b:a 192k -map 0:v:0 -map 1:a:0 -shortest "{output_path}"'
        else:
            # ì˜ìƒë§Œ concat
            cmd = f'ffmpeg -y -f concat -safe 0 -i "{list_file}" -c:v libx264 -preset fast "{output_path}"'

        result = subprocess.run(cmd, capture_output=True, text=True, shell=True)

        if result.returncode == 0:
            print(f"  [OK] section_{section}.mp4")
        else:
            print(f"  [ERROR] ì‹¤íŒ¨: {result.stderr[:200]}")
    finally:
        os.unlink(list_file)


# ============================================================
# Phase 6: FINAL
# ============================================================
def cmd_final(args):
    """ìµœì¢… ë³‘í•© (ì„¹ì…˜ ì—°ê²° + BGM)"""
    print("\nğŸ¬ ìµœì¢… ë³‘í•© ì‹œì‘")

    bgm_volume = args.bgm_volume
    section_gap = getattr(args, 'section_gap', 1.0)  # ì„¹ì…˜ ê°„ gap (ê¸°ë³¸ 1ì´ˆ)
    output_path = OUTPUT_DIR / "final_video.mp4"

    # ì„¹ì…˜ ëª©ë¡ êµ¬ì„±
    sections = get_sections()
    section_files = []
    temp_files = []  # ì‚­ì œí•  ì„ì‹œ íŒŒì¼

    import tempfile

    for idx, section in enumerate(sections):
        section_path = SECTIONS_DIR / f"section_{section}.mp4"
        if not section_path.exists():
            print(f"  [WARN] section_{section}.mp4 ì—†ìŒ")
            continue

        # ëª¨ë“  ì„¹ì…˜ì— 1ì´ˆ gap ì¶”ê°€ (ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€ + ë¬´ìŒ)
        # ë§ˆì§€ë§‰ ì„¹ì…˜ë„ í¬í•¨ - ì˜ìƒ ëì´ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬ë˜ë„ë¡
        if section_gap > 0:
            extended_path = SECTIONS_DIR / f"section_{section}_extended.mp4"

            # tpadë¡œ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥ + apadë¡œ ë¬´ìŒ ì¶”ê°€
            extend_cmd = f'ffmpeg -y -i "{section_path}" -vf "tpad=stop_mode=clone:stop_duration={section_gap}" -af "apad=pad_dur={section_gap}" -c:v libx264 -preset fast -c:a aac "{extended_path}"'

            result = subprocess.run(extend_cmd, capture_output=True, text=True, shell=True)
            if result.returncode == 0:
                section_files.append(extended_path)
                temp_files.append(extended_path)
                print(f"  [OK] section_{section}.mp4 (+{section_gap}s)")
            else:
                section_files.append(section_path)
                print(f"  [OK] section_{section}.mp4 (ì—°ì¥ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©)")
        else:
            section_files.append(section_path)
            print(f"  [OK] section_{section}.mp4")

    if not section_files:
        print("[ERROR] í•©ì„±í•  ì„¹ì…˜ ì—†ìŒ")
        return

    # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for sf in section_files:
            f.write(f"file '{sf}'\n")
        list_file = f.name

    try:
        # BGM ì„ íƒ
        bgm_files = list(BGM_DIR.glob("*.mp3"))

        if bgm_files:
            import random
            bgm_path = random.choice(bgm_files)
            print(f"ğŸµ BGM: {bgm_path.name}")

            # concat + BGM ë¯¹ì‹±
            cmd = f'ffmpeg -y -f concat -safe 0 -i "{list_file}" -i "{bgm_path}" -filter_complex "[1:a]volume={bgm_volume}[bgm];[0:a][bgm]amix=inputs=2:duration=first" -c:v libx264 -preset fast -c:a aac -b:a 192k "{output_path}"'
        else:
            # BGM ì—†ì´
            print("  [INFO] BGM ì—†ìŒ, ë‚˜ë ˆì´ì…˜ë§Œ í¬í•¨")
            cmd = f'ffmpeg -y -f concat -safe 0 -i "{list_file}" -c:v libx264 -preset fast -c:a aac -b:a 192k "{output_path}"'

        result = subprocess.run(cmd, capture_output=True, text=True, shell=True)

        if result.returncode == 0:
            # ìµœì¢… ì˜ìƒ ì •ë³´ ì¶œë ¥
            duration_cmd = f'ffprobe -v error -show_entries format=duration -of csv=p=0 "{output_path}"'
            dur_result = subprocess.run(duration_cmd, capture_output=True, text=True, shell=True)
            duration = float(dur_result.stdout.strip()) if dur_result.stdout.strip() else 0

            print(f"\n[OK] ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“ {output_path}")
            print(f"â±ï¸ ê¸¸ì´: {int(duration//60)}ë¶„ {int(duration%60)}ì´ˆ")
        else:
            print(f"[ERROR] ì‹¤íŒ¨: {result.stderr[:500]}")
    finally:
        os.unlink(list_file)
        # ì„ì‹œ fade íŒŒì¼ ì‚­ì œ
        for tf in temp_files:
            if tf.exists():
                os.unlink(tf)


# ì „í™˜ í´ë¦½ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì„¹ì…˜ ì§ì ‘ ì—°ê²°)
# def composite_transition(trans_idx: int):
#     """ì „í™˜ ë°°ê²½ í•©ì„± (ì‚¬ìš© ì•ˆí•¨)"""
#     pass


# ============================================================
# ìœ í‹¸ë¦¬í‹° ëª…ë ¹ì–´
# ============================================================
def cmd_status(args):
    """í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸"""
    state = load_state()

    print("\nğŸ“Š í”„ë¡œì íŠ¸ ìƒíƒœ")
    print("=" * 50)
    print(f"ì¹´í…Œê³ ë¦¬: {state.get('category', '-')}")
    print(f"ì£¼ì œ: {state.get('topic', '-')}")
    print(f"Phase: {state.get('phase', '-')}")
    print(f"ì—…ë°ì´íŠ¸: {state.get('updated_at', '-')}")
    print("=" * 50)

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    print("\nğŸ“ íŒŒì¼ ìƒíƒœ:")

    checks = [
        ("reading_script.json", SCRIPTS_DIR / "reading_script.json"),
        ("scenes.json", SCRIPTS_DIR / "scenes.json"),
        ("hook.mp3", AUDIO_DIR / "hook.mp3"),
        ("S1.tsx", REMOTION_SCENES_DIR / "S1.tsx"),
        ("final_video.mp4", OUTPUT_DIR / "final_video.mp4"),
    ]

    for name, path in checks:
        status = "[OK]" if path.exists() else "[ERROR]"
        print(f"  {status} {name}")


def cmd_clean(args):
    """output í´ë”ë§Œ ì´ˆê¸°í™” (ì—ì…‹ ìœ ì§€)"""
    import shutil

    print("\nğŸ§¹ output í´ë” ì´ˆê¸°í™”")

    if args.phase:
        print(f"Phase {args.phase} ì´í›„ë§Œ ì‚­ì œ")
        phase_dirs = {
            1: [SCRIPTS_DIR],
            2: [SCRIPTS_DIR],  # scenes.jsonë„ SCRIPTS_DIRì— ì €ì¥
            3: [AUDIO_DIR],
            4: [REMOTION_SCENES_DIR, REMOTION_TRANSITIONS_DIR],
            5: [RENDERS_DIR, COMPOSITE_DIR],
        }
        for p in range(args.phase, 6):
            for d in phase_dirs.get(p, []):
                if d.exists():
                    if d in [REMOTION_SCENES_DIR, REMOTION_TRANSITIONS_DIR]:
                        for f in d.glob("*.tsx"):
                            f.unlink()
                            print(f"  ğŸ—‘ï¸ {f.name}")
                    else:
                        shutil.rmtree(d)
                        print(f"  ğŸ—‘ï¸ {d}")
    else:
        # output ì „ì²´ ì‚­ì œ
        dirs_to_clean = [
            SCRIPTS_DIR, AUDIO_DIR,
            BACKGROUNDS_DIR, RENDERS_DIR, COMPOSITE_DIR
        ]

        for d in dirs_to_clean:
            if d.exists():
                shutil.rmtree(d)
                print(f"  - {d.name}")

        # Remotion ì”¬/ì „í™˜ ì‚­ì œ
        for f in REMOTION_SCENES_DIR.glob("S*.tsx"):
            f.unlink()
            print(f"  ğŸ—‘ï¸ scenes/{f.name}")

        for f in REMOTION_TRANSITIONS_DIR.glob("T*.tsx"):
            f.unlink()
            print(f"  ğŸ—‘ï¸ transitions/{f.name}")

    # ë””ë ‰í† ë¦¬ ì¬ìƒì„±
    ensure_dirs()

    print("\n[OK] output ì´ˆê¸°í™” ì™„ë£Œ!")


def cmd_init(args):
    """í”„ë¡œì íŠ¸ ì™„ì „ ì´ˆê¸°í™” (ì—ì…‹ í¬í•¨)"""
    import shutil

    print("\n[INIT] Project Full Reset")
    print("=" * 50)

    # 1. output í´ë” ì´ˆê¸°í™”
    print("\n[1/4] Cleaning output folders...")
    for d in [SCRIPTS_DIR, AUDIO_DIR, BACKGROUNDS_DIR, VISUAL_DIR, RENDERS_DIR, SCENES_DIR, SECTIONS_DIR, TRANSITIONS_DIR]:
        if d.exists():
            shutil.rmtree(d)
            print(f"  - {d.name}")

    # final_video.mp4 ì‚­ì œ
    final_video = OUTPUT_DIR / "final_video.mp4"
    if final_video.exists():
        final_video.unlink()
        print(f"  - final_video.mp4")

    # asset_catalog.csv ì‚­ì œ
    catalog = OUTPUT_DIR / "asset_catalog.csv"
    if catalog.exists():
        catalog.unlink()
        print(f"  - asset_catalog.csv")

    # 2. Remotion ì”¬/ì „í™˜ ì‚­ì œ
    print("\n[2/4] Cleaning Remotion code...")
    scene_count = 0
    for f in REMOTION_SCENES_DIR.glob("S*.tsx"):
        f.unlink()
        scene_count += 1
    print(f"  - scenes/*.tsx ({scene_count})")

    trans_count = 0
    for f in REMOTION_TRANSITIONS_DIR.glob("T*.tsx"):
        f.unlink()
        trans_count += 1
    print(f"  - transitions/*.tsx ({trans_count})")

    # Root.tsx ì´ˆê¸°í™”
    root_path = REMOTION_DIR / "src" / "Root.tsx"
    root_content = '''import React from "react";
// import { Composition } from "remotion";
// Scenes and Transitions will be auto-generated by pipeline.py update-root

export const RemotionRoot: React.FC = () => {
  return (
    <>
      {/* Compositions will be added here by pipeline.py update-root */}
    </>
  );
};
'''
    with open(root_path, 'w', encoding='utf-8') as f:
        f.write(root_content)
    print(f"  - Root.tsx reset")

    # 3. assets í´ë” ë‚´ìš© ì‚­ì œ
    print("\n[3/4] Cleaning assets folders...")
    asset_categories = ["icons", "maps", "portraits", "artifacts", "backgrounds"]

    for cat in asset_categories:
        cat_dir = ASSETS_DIR / cat
        if cat_dir.exists():
            count = 0
            for f in cat_dir.iterdir():
                if f.is_file():
                    f.unlink()
                    count += 1
            if count > 0:
                print(f"  - assets/{cat}/ ({count})")

    # remotion/public/assets ë„ ì •ë¦¬
    for cat in asset_categories:
        cat_dir = REMOTION_ASSETS_DIR / cat
        if cat_dir.exists():
            count = 0
            for f in cat_dir.iterdir():
                if f.is_file():
                    f.unlink()
                    count += 1
            if count > 0:
                print(f"  - remotion/public/assets/{cat}/ ({count})")

    # remotion/out í´ë” ì •ë¦¬
    remotion_out_dir = REMOTION_DIR / "out"
    if remotion_out_dir.exists():
        count = 0
        for f in remotion_out_dir.iterdir():
            if f.is_file():
                f.unlink()
                count += 1
            elif f.is_dir():
                shutil.rmtree(f)
                count += 1
        if count > 0:
            print(f"  - remotion/out/ ({count})")

    # 4. state.json ì´ˆê¸°í™”
    print("\n[4/4] Resetting state.json...")
    initial_state = {
        "project_id": None,
        "category": None,
        "topic": None,
        "duration_target": 300,
        "aspect_ratio": "16:9",
        "voice": "nova",
        "phase": "initialized",
        "current_step": 0,
        "scenes_count": 0,
        "created_at": None,
        "updated_at": None
    }
    save_json(STATE_FILE, initial_state)

    # ë””ë ‰í† ë¦¬ ì¬ìƒì„±
    ensure_dirs()

    print("\n" + "=" * 50)
    print("[OK] Project initialization complete!")
    print("\nTo start a new project:")
    print("  1. Use /script-writer skill for script")
    print("  2. Use scene-director agent for scene split")
    print("  3. Generate assets and save to assets/ folder")


def cmd_download_assets(args):
    """Supabaseì—ì„œ ì—ì…‹ ë‹¤ìš´ë¡œë“œ"""
    print("\n[DOWNLOAD] Downloading assets from Supabase...")

    try:
        from supabase import create_client
    except ImportError:
        print("[ERROR] supabase package required: pip install supabase")
        return

    # Supabase REST API URL (not PostgreSQL URL)
    SUPABASE_URL = "https://lgpkjmxasrcuvycxefxh.supabase.co"
    SUPABASE_KEY = os.environ.get("SUPABASE_ANON_KEY") or os.environ.get("SUPABASE_SERVICE_KEY")

    if not SUPABASE_KEY:
        print("[ERROR] SUPABASE_ANON_KEY or SUPABASE_SERVICE_KEY environment variable required")
        return

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    # í•„ìš”í•œ ì—ì…‹ ìˆ˜ì§‘
    required_assets = set()
    for scene_file in SCRIPTS_DIR.glob("s*.json"):
        if scene_file.name in ["scenes.json", "scenes_minimal.json"]:
            continue
        scene_data = load_json(scene_file)
        if scene_data:
            for elem in scene_data.get("required_elements", []):
                asset = elem.get("asset")
                if asset:
                    required_assets.add(asset)

    print(f"[INFO] {len(required_assets)} assets required")

    # Supabaseì—ì„œ ì—ì…‹ ì •ë³´ ì¡°íšŒ
    response = supabase.table("assets").select("*").execute()
    all_assets = {a["asset_id"]: a for a in response.data}

    # ë‹¤ìš´ë¡œë“œ
    downloaded = 0
    for asset_id in required_assets:
        if asset_id not in all_assets:
            print(f"[WARN] {asset_id} not found in database")
            continue

        asset_info = all_assets[asset_id]
        file_path = asset_info["file_path"]  # e.g., "icons/clock_icon.png"

        local_path = ASSETS_DIR / file_path
        remotion_path = REMOTION_ASSETS_DIR / file_path

        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if local_path.exists():
            continue

        # Supabase Storageì—ì„œ ë‹¤ìš´ë¡œë“œ
        try:
            bucket_name = "history-assets"
            data = supabase.storage.from_(bucket_name).download(file_path)

            # ë¡œì»¬ ì €ì¥
            local_path.parent.mkdir(parents=True, exist_ok=True)
            with open(local_path, 'wb') as f:
                f.write(data)

            # Remotionì—ë„ ë³µì‚¬
            remotion_path.parent.mkdir(parents=True, exist_ok=True)
            with open(remotion_path, 'wb') as f:
                f.write(data)

            downloaded += 1
            print(f"[OK] {file_path}")
        except Exception as e:
            print(f"[ERROR] {asset_id}: {str(e)[:50]}")

    print(f"\n[DONE] Downloaded {downloaded} new assets")



    """ì—ì…‹ ì¹´íƒˆë¡œê·¸ ìƒì„±"""
    print("\n[CATALOG] Generating asset catalog...")

    catalog = {
        "icons": [],
        "portraits": [],
        "maps": [],
        "generated_at": datetime.now().isoformat()
    }

    categories = ["icons", "portraits", "maps"]

    for cat in categories:
        cat_dir = ASSETS_DIR / cat
        if cat_dir.exists():
            for f in cat_dir.glob("*.png"):
                catalog[cat].append({
                    "name": f.stem,
                    "path": f"assets/{cat}/{f.name}"
                })
            for f in cat_dir.glob("*.jpg"):
                catalog[cat].append({
                    "name": f.stem,
                    "path": f"assets/{cat}/{f.name}"
                })

    output_path = OUTPUT_DIR / "asset_catalog.csv"
    save_json(output_path, catalog)

    total = sum(len(catalog[c]) for c in categories)
    print(f"[OK] Catalog generated ({total} assets)")


# ============================================================
# ë©”ì¸
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description="Video Story Maker Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")

    # Phase 2: merge-scenes
    p_merge = subparsers.add_parser("merge-scenes", help="ì”¬ íŒŒì¼ ë³‘í•©")
    p_merge.set_defaults(func=cmd_merge_scenes)

    # Phase 3: audio
    p_audio = subparsers.add_parser("audio", help="TTS ìƒì„± + Whisper")
    p_audio.add_argument("--voice", default="nova", help="TTS ìŒì„± (ê¸°ë³¸: nova)")
    p_audio.add_argument("--force", action="store_true", help="ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°")
    p_audio.set_defaults(func=cmd_audio)

    # Phase 3.5: srt-timing
    p_srt = subparsers.add_parser("srt-timing", help="SRT íƒ€ì´ë° ìƒì„±")
    p_srt.set_defaults(func=cmd_srt_timing)

    # Phase 4: update-root
    p_root = subparsers.add_parser("update-root", help="Root.tsx ìë™ ì—…ë°ì´íŠ¸")
    p_root.set_defaults(func=cmd_update_root)

    # Phase 5: render
    p_render = subparsers.add_parser("render", help="Remotion ë Œë”ë§ (ê¸°ë³¸: ë°°ê²½ í¬í•¨)")
    p_render.add_argument("--section", "-s", help="íŠ¹ì • ì„¹ì…˜ë§Œ")
    p_render.add_argument("--scene", help="íŠ¹ì • ì”¬ë§Œ")
    p_render.add_argument("--concurrency", "-c", type=int, default=4, help="ë™ì‹œì„± (ê¸°ë³¸: 4)")
    p_render.add_argument("--transparent", "-t", action="store_true", help="íˆ¬ëª… ë°°ê²½ ë Œë”ë§ (WebM, FFmpeg í•©ì„± í•„ìš”)")
    p_render.set_defaults(func=cmd_render)

    # Phase 5: composite
    p_composite = subparsers.add_parser("composite", help="ë°°ê²½ í•©ì„±")
    p_composite.add_argument("--section", "-s", help="íŠ¹ì • ì„¹ì…˜ë§Œ")
    p_composite.set_defaults(func=cmd_composite)

    # Phase 5: section-merge
    p_section = subparsers.add_parser("section-merge", help="ì„¹ì…˜ í•©ì„±")
    p_section.add_argument("--section", "-s", help="íŠ¹ì • ì„¹ì…˜ë§Œ")
    p_section.set_defaults(func=cmd_section_merge)

    # Phase 6: final
    p_final = subparsers.add_parser("final", help="ìµœì¢… ë³‘í•©")
    p_final.add_argument("--bgm-volume", type=float, default=0.08, help="BGM ë³¼ë¥¨ (ê¸°ë³¸: 0.08)")
    p_final.add_argument("--section-gap", type=float, default=1.0, help="ì„¹ì…˜ ê°„ gap ì‹œê°„ - ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€ (ê¸°ë³¸: 1ì´ˆ, 0ì´ë©´ ë¹„í™œì„±í™”)")
    p_final.set_defaults(func=cmd_final)

    # ìœ í‹¸ë¦¬í‹°
    p_status = subparsers.add_parser("status", help="í”„ë¡œì íŠ¸ ìƒíƒœ")
    p_status.set_defaults(func=cmd_status)

    p_clean = subparsers.add_parser("clean", help="output í´ë” ì´ˆê¸°í™” (ì—ì…‹ ìœ ì§€)")
    p_clean.add_argument("--phase", type=int, help="íŠ¹ì • Phase ì´í›„ë§Œ")
    p_clean.set_defaults(func=cmd_clean)

    p_init = subparsers.add_parser("init", help="í”„ë¡œì íŠ¸ ì™„ì „ ì´ˆê¸°í™” (ì—ì…‹ í¬í•¨)")
    p_init.set_defaults(func=cmd_init)

    # asset-catalog ëª…ë ¹ì–´ëŠ” asset-checker ìŠ¤í‚¬ë¡œ ëŒ€ì²´ë¨
    # p_catalog = subparsers.add_parser("asset-catalog", help="ì—ì…‹ ì¹´íƒˆë¡œê·¸ ìƒì„±")
    # p_catalog.set_defaults(func=cmd_asset_catalog)

    p_download = subparsers.add_parser("download-assets", help="Supabaseì—ì„œ ì—ì…‹ ë‹¤ìš´ë¡œë“œ")
    p_download.set_defaults(func=cmd_download_assets)

    p_validate = subparsers.add_parser("validate-parts", help="Part ë¶„í•  ì •ë³´ ê²€ì¦")
    p_validate.set_defaults(func=cmd_validate_parts)

    # íŒŒì‹± ë° ì‹¤í–‰
    args = parser.parse_args()

    if args.command is None:
        parser.print_help()
        return

    ensure_dirs()
    args.func(args)


if __name__ == "__main__":
    main()
